{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Semi_Supervised_to_Supervised.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPdW2r926BdaPHe/MYhRvJ/",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/prasadshreyas/CS7290-Causal-ML-PyTorch/blob/main/Semi_Supervised_to_Supervised.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip3 install pyro-ppl"
      ],
      "metadata": {
        "id": "3itEcadhLC8H",
        "outputId": "a564d570-f30a-4547-e1a3-881bf0b5599c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pyro-ppl\n",
            "  Downloading pyro_ppl-1.8.1-py3-none-any.whl (718 kB)\n",
            "\u001b[K     |████████████████████████████████| 718 kB 5.3 MB/s \n",
            "\u001b[?25hCollecting pyro-api>=0.1.1\n",
            "  Downloading pyro_api-0.1.2-py3-none-any.whl (11 kB)\n",
            "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from pyro-ppl) (1.11.0+cu113)\n",
            "Requirement already satisfied: tqdm>=4.36 in /usr/local/lib/python3.7/dist-packages (from pyro-ppl) (4.64.0)\n",
            "Requirement already satisfied: numpy>=1.7 in /usr/local/lib/python3.7/dist-packages (from pyro-ppl) (1.21.6)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from pyro-ppl) (3.3.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.11.0->pyro-ppl) (4.2.0)\n",
            "Installing collected packages: pyro-api, pyro-ppl\n",
            "Successfully installed pyro-api-0.1.2 pyro-ppl-1.8.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Github - ss-vae.py\n",
        "--"
      ],
      "metadata": {
        "id": "7-qpDFXNd4jO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Copyright (c) 2017-2019 Uber Technologies, Inc.\n",
        "# SPDX-License-Identifier: Apache-2.0\n",
        "\n",
        "import argparse\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from utils.custom_mlp import MLP, Exp\n",
        "from utils.mnist_cached import MNISTCached, mkdir_p, setup_data_loaders\n",
        "from utils.vae_plots import mnist_test_tsne_ssvae, plot_conditional_samples_ssvae\n",
        "from visdom import Visdom\n",
        "\n",
        "import pyro\n",
        "import pyro.distributions as dist\n",
        "from pyro.contrib.examples.util import print_and_log\n",
        "from pyro.infer import (\n",
        "    SVI,\n",
        "    JitTrace_ELBO,\n",
        "    JitTraceEnum_ELBO,\n",
        "    Trace_ELBO,\n",
        "    TraceEnum_ELBO,\n",
        "    config_enumerate,\n",
        ")\n",
        "from pyro.optim import Adam\n",
        "\n",
        "\n",
        "class SSVAE(nn.Module):\n",
        "    \"\"\"\n",
        "    This class encapsulates the parameters (neural networks) and models & guides needed to train a\n",
        "    semi-supervised variational auto-encoder on the MNIST image dataset\n",
        "\n",
        "    :param output_size: size of the tensor representing the class label (10 for MNIST since\n",
        "                        we represent the class labels as a one-hot vector with 10 components)\n",
        "    :param input_size: size of the tensor representing the image (28*28 = 784 for our MNIST dataset\n",
        "                       since we flatten the images and scale the pixels to be in [0,1])\n",
        "    :param z_dim: size of the tensor representing the latent random variable z\n",
        "                  (handwriting style for our MNIST dataset)\n",
        "    :param hidden_layers: a tuple (or list) of MLP layers to be used in the neural networks\n",
        "                          representing the parameters of the distributions in our model\n",
        "    :param use_cuda: use GPUs for faster training\n",
        "    :param aux_loss_multiplier: the multiplier to use with the auxiliary loss\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        output_size=10,\n",
        "        input_size=784,\n",
        "        z_dim=50,\n",
        "        hidden_layers=(500,),\n",
        "        config_enum=None,\n",
        "        use_cuda=False,\n",
        "        aux_loss_multiplier=None,\n",
        "    ):\n",
        "\n",
        "        super().__init__()\n",
        "\n",
        "        # initialize the class with all arguments provided to the constructor\n",
        "        self.output_size = output_size\n",
        "        self.input_size = input_size\n",
        "        self.z_dim = z_dim\n",
        "        self.hidden_layers = hidden_layers\n",
        "        self.allow_broadcast = config_enum == \"parallel\"\n",
        "        self.use_cuda = use_cuda\n",
        "        self.aux_loss_multiplier = aux_loss_multiplier\n",
        "\n",
        "        # define and instantiate the neural networks representing\n",
        "        # the paramters of various distributions in the model\n",
        "        self.setup_networks()\n",
        "\n",
        "    def setup_networks(self):\n",
        "\n",
        "        z_dim = self.z_dim\n",
        "        hidden_sizes = self.hidden_layers\n",
        "\n",
        "        # define the neural networks used later in the model and the guide.\n",
        "        # these networks are MLPs (multi-layered perceptrons or simple feed-forward networks)\n",
        "        # where the provided activation parameter is used on every linear layer except\n",
        "        # for the output layer where we use the provided output_activation parameter\n",
        "        self.encoder_y = MLP(\n",
        "            [self.input_size] + hidden_sizes + [self.output_size],\n",
        "            activation=nn.Softplus,\n",
        "            output_activation=nn.Softmax,\n",
        "            allow_broadcast=self.allow_broadcast,\n",
        "            use_cuda=self.use_cuda,\n",
        "        )\n",
        "\n",
        "        # a split in the final layer's size is used for multiple outputs\n",
        "        # and potentially applying separate activation functions on them\n",
        "        # e.g. in this network the final output is of size [z_dim,z_dim]\n",
        "        # to produce loc and scale, and apply different activations [None,Exp] on them\n",
        "        self.encoder_z = MLP(\n",
        "            [self.input_size + self.output_size] + hidden_sizes + [[z_dim, z_dim]],\n",
        "            activation=nn.Softplus,\n",
        "            output_activation=[None, Exp],\n",
        "            allow_broadcast=self.allow_broadcast,\n",
        "            use_cuda=self.use_cuda,\n",
        "        )\n",
        "\n",
        "        self.decoder = MLP(\n",
        "            [z_dim + self.output_size] + hidden_sizes + [self.input_size],\n",
        "            activation=nn.Softplus,\n",
        "            output_activation=nn.Sigmoid,\n",
        "            allow_broadcast=self.allow_broadcast,\n",
        "            use_cuda=self.use_cuda,\n",
        "        )\n",
        "\n",
        "        # using GPUs for faster training of the networks\n",
        "        if self.use_cuda:\n",
        "            self.cuda()\n",
        "\n",
        "    def model(self, xs, ys=None):\n",
        "        \"\"\"\n",
        "        The model corresponds to the following generative process:\n",
        "        p(z) = normal(0,I)              # handwriting style (latent)\n",
        "        p(y|x) = categorical(I/10.)     # which digit (semi-supervised)\n",
        "        p(x|y,z) = bernoulli(loc(y,z))   # an image\n",
        "        loc is given by a neural network  `decoder`\n",
        "\n",
        "        :param xs: a batch of scaled vectors of pixels from an image\n",
        "        :param ys: (optional) a batch of the class labels i.e.\n",
        "                   the digit corresponding to the image(s)\n",
        "        :return: None\n",
        "        \"\"\"\n",
        "        # register this pytorch module and all of its sub-modules with pyro\n",
        "        pyro.module(\"ss_vae\", self)\n",
        "\n",
        "        batch_size = xs.size(0)\n",
        "        options = dict(dtype=xs.dtype, device=xs.device)\n",
        "        with pyro.plate(\"data\"):\n",
        "\n",
        "            # sample the handwriting style from the constant prior distribution\n",
        "            prior_loc = torch.zeros(batch_size, self.z_dim, **options)\n",
        "            prior_scale = torch.ones(batch_size, self.z_dim, **options)\n",
        "            zs = pyro.sample(\"z\", dist.Normal(prior_loc, prior_scale).to_event(1))\n",
        "\n",
        "            # if the label y (which digit to write) is supervised, sample from the\n",
        "            # constant prior, otherwise, observe the value (i.e. score it against the constant prior)\n",
        "            alpha_prior = torch.ones(batch_size, self.output_size, **options) / (\n",
        "                1.0 * self.output_size\n",
        "            )\n",
        "            ys = pyro.sample(\"y\", dist.OneHotCategorical(alpha_prior), obs=ys)\n",
        "\n",
        "            # Finally, score the image (x) using the handwriting style (z) and\n",
        "            # the class label y (which digit to write) against the\n",
        "            # parametrized distribution p(x|y,z) = bernoulli(decoder(y,z))\n",
        "            # where `decoder` is a neural network. We disable validation\n",
        "            # since the decoder output is a relaxed Bernoulli value.\n",
        "            loc = self.decoder.forward([zs, ys])\n",
        "            pyro.sample(\n",
        "                \"x\", dist.Bernoulli(loc, validate_args=False).to_event(1), obs=xs\n",
        "            )\n",
        "            # return the loc so we can visualize it later\n",
        "            return loc\n",
        "\n",
        "    def guide(self, xs, ys=None):\n",
        "        \"\"\"\n",
        "        The guide corresponds to the following:\n",
        "        q(y|x) = categorical(alpha(x))              # infer digit from an image\n",
        "        q(z|x,y) = normal(loc(x,y),scale(x,y))       # infer handwriting style from an image and the digit\n",
        "        loc, scale are given by a neural network `encoder_z`\n",
        "        alpha is given by a neural network `encoder_y`\n",
        "\n",
        "        :param xs: a batch of scaled vectors of pixels from an image\n",
        "        :param ys: (optional) a batch of the class labels i.e.\n",
        "                   the digit corresponding to the image(s)\n",
        "        :return: None\n",
        "        \"\"\"\n",
        "        # inform Pyro that the variables in the batch of xs, ys are conditionally independent\n",
        "        with pyro.plate(\"data\"):\n",
        "\n",
        "            # if the class label (the digit) is not supervised, sample\n",
        "            # (and score) the digit with the variational distribution\n",
        "            # q(y|x) = categorical(alpha(x))\n",
        "            if ys is None:\n",
        "                alpha = self.encoder_y.forward(xs)\n",
        "                ys = pyro.sample(\"y\", dist.OneHotCategorical(alpha))\n",
        "\n",
        "            # sample (and score) the latent handwriting-style with the variational\n",
        "            # distribution q(z|x,y) = normal(loc(x,y),scale(x,y))\n",
        "            loc, scale = self.encoder_z.forward([xs, ys])\n",
        "            pyro.sample(\"z\", dist.Normal(loc, scale).to_event(1))\n",
        "\n",
        "    def classifier(self, xs):\n",
        "        \"\"\"\n",
        "        classify an image (or a batch of images)\n",
        "\n",
        "        :param xs: a batch of scaled vectors of pixels from an image\n",
        "        :return: a batch of the corresponding class labels (as one-hots)\n",
        "        \"\"\"\n",
        "        # use the trained model q(y|x) = categorical(alpha(x))\n",
        "        # compute all class probabilities for the image(s)\n",
        "        alpha = self.encoder_y.forward(xs)\n",
        "\n",
        "        # get the index (digit) that corresponds to\n",
        "        # the maximum predicted class probability\n",
        "        res, ind = torch.topk(alpha, 1)\n",
        "\n",
        "        # convert the digit(s) to one-hot tensor(s)\n",
        "        ys = torch.zeros_like(alpha).scatter_(1, ind, 1.0)\n",
        "        return ys\n",
        "\n",
        "    def model_classify(self, xs, ys=None):\n",
        "        \"\"\"\n",
        "        this model is used to add an auxiliary (supervised) loss as described in the\n",
        "        Kingma et al., \"Semi-Supervised Learning with Deep Generative Models\".\n",
        "        \"\"\"\n",
        "        # register all pytorch (sub)modules with pyro\n",
        "        pyro.module(\"ss_vae\", self)\n",
        "\n",
        "        # inform Pyro that the variables in the batch of xs, ys are conditionally independent\n",
        "        with pyro.plate(\"data\"):\n",
        "            # this here is the extra term to yield an auxiliary loss that we do gradient descent on\n",
        "            if ys is not None:\n",
        "                alpha = self.encoder_y.forward(xs)\n",
        "                with pyro.poutine.scale(scale=self.aux_loss_multiplier):\n",
        "                    pyro.sample(\"y_aux\", dist.OneHotCategorical(alpha), obs=ys)\n",
        "\n",
        "    def guide_classify(self, xs, ys=None):\n",
        "        \"\"\"\n",
        "        dummy guide function to accompany model_classify in inference\n",
        "        \"\"\"\n",
        "        pass\n",
        "\n",
        "\n",
        "def run_inference_for_epoch(data_loaders, losses, periodic_interval_batches):\n",
        "    \"\"\"\n",
        "    runs the inference algorithm for an epoch\n",
        "    returns the values of all losses separately on supervised and unsupervised parts\n",
        "    \"\"\"\n",
        "    num_losses = len(losses)\n",
        "\n",
        "    # compute number of batches for an epoch\n",
        "    sup_batches = len(data_loaders[\"sup\"])\n",
        "    unsup_batches = len(data_loaders[\"unsup\"])\n",
        "    batches_per_epoch = sup_batches + unsup_batches\n",
        "\n",
        "    # initialize variables to store loss values\n",
        "    epoch_losses_sup = [0.0] * num_losses\n",
        "    epoch_losses_unsup = [0.0] * num_losses\n",
        "\n",
        "    # setup the iterators for training data loaders\n",
        "    sup_iter = iter(data_loaders[\"sup\"])\n",
        "    unsup_iter = iter(data_loaders[\"unsup\"])\n",
        "\n",
        "    # count the number of supervised batches seen in this epoch\n",
        "    ctr_sup = 0\n",
        "    for i in range(batches_per_epoch):\n",
        "\n",
        "        # whether this batch is supervised or not\n",
        "        is_supervised = (i % periodic_interval_batches == 1) and ctr_sup < sup_batches\n",
        "\n",
        "        # extract the corresponding batch\n",
        "        if is_supervised:\n",
        "            (xs, ys) = next(sup_iter)\n",
        "            ctr_sup += 1\n",
        "        else:\n",
        "            (xs, ys) = next(unsup_iter)\n",
        "\n",
        "        # run the inference for each loss with supervised or un-supervised\n",
        "        # data as arguments\n",
        "        for loss_id in range(num_losses):\n",
        "            if is_supervised:\n",
        "                new_loss = losses[loss_id].step(xs, ys)\n",
        "                epoch_losses_sup[loss_id] += new_loss\n",
        "            else:\n",
        "                new_loss = losses[loss_id].step(xs)\n",
        "                epoch_losses_unsup[loss_id] += new_loss\n",
        "\n",
        "    # return the values of all losses\n",
        "    return epoch_losses_sup, epoch_losses_unsup\n",
        "\n",
        "\n",
        "def get_accuracy(data_loader, classifier_fn, batch_size):\n",
        "    \"\"\"\n",
        "    compute the accuracy over the supervised training set or the testing set\n",
        "    \"\"\"\n",
        "    predictions, actuals = [], []\n",
        "\n",
        "    # use the appropriate data loader\n",
        "    for (xs, ys) in data_loader:\n",
        "        # use classification function to compute all predictions for each batch\n",
        "        predictions.append(classifier_fn(xs))\n",
        "        actuals.append(ys)\n",
        "\n",
        "    # compute the number of accurate predictions\n",
        "    accurate_preds = 0\n",
        "    for pred, act in zip(predictions, actuals):\n",
        "        for i in range(pred.size(0)):\n",
        "            v = torch.sum(pred[i] == act[i])\n",
        "            accurate_preds += v.item() == 10\n",
        "\n",
        "    # calculate the accuracy between 0 and 1\n",
        "    accuracy = (accurate_preds * 1.0) / (len(predictions) * batch_size)\n",
        "    return accuracy\n",
        "\n",
        "\n",
        "def visualize(ss_vae, viz, test_loader):\n",
        "    if viz:\n",
        "        plot_conditional_samples_ssvae(ss_vae, viz)\n",
        "        mnist_test_tsne_ssvae(ssvae=ss_vae, test_loader=test_loader)\n",
        "\n",
        "\n",
        "def main(args):\n",
        "    \"\"\"\n",
        "    run inference for SS-VAE\n",
        "    :param args: arguments for SS-VAE\n",
        "    :return: None\n",
        "    \"\"\"\n",
        "    if args.seed is not None:\n",
        "        pyro.set_rng_seed(args.seed)\n",
        "\n",
        "    viz = None\n",
        "    if args.visualize:\n",
        "        viz = Visdom()\n",
        "        mkdir_p(\"./vae_results\")\n",
        "\n",
        "    # batch_size: number of images (and labels) to be considered in a batch\n",
        "    ss_vae = SSVAE(\n",
        "        z_dim=args.z_dim,\n",
        "        hidden_layers=args.hidden_layers,\n",
        "        use_cuda=args.cuda,\n",
        "        config_enum=args.enum_discrete,\n",
        "        aux_loss_multiplier=args.aux_loss_multiplier,\n",
        "    )\n",
        "\n",
        "    # setup the optimizer\n",
        "    adam_params = {\"lr\": args.learning_rate, \"betas\": (args.beta_1, 0.999)}\n",
        "    optimizer = Adam(adam_params)\n",
        "\n",
        "    # set up the loss(es) for inference. wrapping the guide in config_enumerate builds the loss as a sum\n",
        "    # by enumerating each class label for the sampled discrete categorical distribution in the model\n",
        "    guide = config_enumerate(ss_vae.guide, args.enum_discrete, expand=True)\n",
        "    Elbo = JitTraceEnum_ELBO if args.jit else TraceEnum_ELBO\n",
        "    elbo = Elbo(max_plate_nesting=1, strict_enumeration_warning=False)\n",
        "    loss_basic = SVI(ss_vae.model, guide, optimizer, loss=elbo)\n",
        "\n",
        "    # build a list of all losses considered\n",
        "    losses = [loss_basic]\n",
        "\n",
        "    # aux_loss: whether to use the auxiliary loss from NIPS 14 paper (Kingma et al)\n",
        "    if args.aux_loss:\n",
        "        elbo = JitTrace_ELBO() if args.jit else Trace_ELBO()\n",
        "        loss_aux = SVI(\n",
        "            ss_vae.model_classify, ss_vae.guide_classify, optimizer, loss=elbo\n",
        "        )\n",
        "        losses.append(loss_aux)\n",
        "\n",
        "    try:\n",
        "        # setup the logger if a filename is provided\n",
        "        logger = open(args.logfile, \"w\") if args.logfile else None\n",
        "\n",
        "        data_loaders = setup_data_loaders(\n",
        "            MNISTCached, args.cuda, args.batch_size, sup_num=args.sup_num\n",
        "        )\n",
        "\n",
        "        # how often would a supervised batch be encountered during inference\n",
        "        # e.g. if sup_num is 3000, we would have every 16th = int(50000/3000) batch supervised\n",
        "        # until we have traversed through the all supervised batches\n",
        "        periodic_interval_batches = int(\n",
        "            MNISTCached.train_data_size / (1.0 * args.sup_num)\n",
        "        )\n",
        "\n",
        "        # number of unsupervised examples\n",
        "        unsup_num = MNISTCached.train_data_size - args.sup_num\n",
        "\n",
        "        # initializing local variables to maintain the best validation accuracy\n",
        "        # seen across epochs over the supervised training set\n",
        "        # and the corresponding testing set and the state of the networks\n",
        "        best_valid_acc, corresponding_test_acc = 0.0, 0.0\n",
        "\n",
        "        # run inference for a certain number of epochs\n",
        "        for i in range(0, args.num_epochs):\n",
        "\n",
        "            # get the losses for an epoch\n",
        "            epoch_losses_sup, epoch_losses_unsup = run_inference_for_epoch(\n",
        "                data_loaders, losses, periodic_interval_batches\n",
        "            )\n",
        "\n",
        "            # compute average epoch losses i.e. losses per example\n",
        "            avg_epoch_losses_sup = map(lambda v: v / args.sup_num, epoch_losses_sup)\n",
        "            avg_epoch_losses_unsup = map(lambda v: v / unsup_num, epoch_losses_unsup)\n",
        "\n",
        "            # store the loss and validation/testing accuracies in the logfile\n",
        "            str_loss_sup = \" \".join(map(str, avg_epoch_losses_sup))\n",
        "            str_loss_unsup = \" \".join(map(str, avg_epoch_losses_unsup))\n",
        "\n",
        "            str_print = \"{} epoch: avg losses {}\".format(\n",
        "                i, \"{} {}\".format(str_loss_sup, str_loss_unsup)\n",
        "            )\n",
        "\n",
        "            validation_accuracy = get_accuracy(\n",
        "                data_loaders[\"valid\"], ss_vae.classifier, args.batch_size\n",
        "            )\n",
        "            str_print += \" validation accuracy {}\".format(validation_accuracy)\n",
        "\n",
        "            # this test accuracy is only for logging, this is not used\n",
        "            # to make any decisions during training\n",
        "            test_accuracy = get_accuracy(\n",
        "                data_loaders[\"test\"], ss_vae.classifier, args.batch_size\n",
        "            )\n",
        "            str_print += \" test accuracy {}\".format(test_accuracy)\n",
        "\n",
        "            # update the best validation accuracy and the corresponding\n",
        "            # testing accuracy and the state of the parent module (including the networks)\n",
        "            if best_valid_acc < validation_accuracy:\n",
        "                best_valid_acc = validation_accuracy\n",
        "                corresponding_test_acc = test_accuracy\n",
        "\n",
        "            print_and_log(logger, str_print)\n",
        "\n",
        "        final_test_accuracy = get_accuracy(\n",
        "            data_loaders[\"test\"], ss_vae.classifier, args.batch_size\n",
        "        )\n",
        "        print_and_log(\n",
        "            logger,\n",
        "            \"best validation accuracy {} corresponding testing accuracy {} \"\n",
        "            \"last testing accuracy {}\".format(\n",
        "                best_valid_acc, corresponding_test_acc, final_test_accuracy\n",
        "            ),\n",
        "        )\n",
        "\n",
        "        # visualize the conditional samples\n",
        "        visualize(ss_vae, viz, data_loaders[\"test\"])\n",
        "    finally:\n",
        "        # close the logger file object if we opened it earlier\n",
        "        if args.logfile:\n",
        "            logger.close()\n",
        "\n",
        "\n",
        "EXAMPLE_RUN = (\n",
        "    \"example run: python ss_vae_M2.py --seed 0 --cuda -n 2 --aux-loss -alm 46 -enum parallel \"\n",
        "    \"-sup 3000 -zd 50 -hl 500 -lr 0.00042 -b1 0.95 -bs 200 -log ./tmp.log\"\n",
        ")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    assert pyro.__version__.startswith(\"1.8.1\")\n",
        "\n",
        "    parser = argparse.ArgumentParser(description=\"SS-VAE\\n{}\".format(EXAMPLE_RUN))\n",
        "\n",
        "    parser.add_argument(\n",
        "        \"--cuda\", action=\"store_true\", help=\"use GPU(s) to speed up training\"\n",
        "    )\n",
        "    parser.add_argument(\n",
        "        \"--jit\", action=\"store_true\", help=\"use PyTorch jit to speed up training\"\n",
        "    )\n",
        "    parser.add_argument(\n",
        "        \"-n\", \"--num-epochs\", default=50, type=int, help=\"number of epochs to run\"\n",
        "    )\n",
        "    parser.add_argument(\n",
        "        \"--aux-loss\",\n",
        "        action=\"store_true\",\n",
        "        help=\"whether to use the auxiliary loss from NIPS 14 paper \"\n",
        "        \"(Kingma et al). It is not used by default \",\n",
        "    )\n",
        "    parser.add_argument(\n",
        "        \"-alm\",\n",
        "        \"--aux-loss-multiplier\",\n",
        "        default=46,\n",
        "        type=float,\n",
        "        help=\"the multiplier to use with the auxiliary loss\",\n",
        "    )\n",
        "    parser.add_argument(\n",
        "        \"-enum\",\n",
        "        \"--enum-discrete\",\n",
        "        default=\"parallel\",\n",
        "        help=\"parallel, sequential or none. uses parallel enumeration by default\",\n",
        "    )\n",
        "    parser.add_argument(\n",
        "        \"-sup\",\n",
        "        \"--sup-num\",\n",
        "        default=3000,\n",
        "        type=float,\n",
        "        help=\"supervised amount of the data i.e. \"\n",
        "        \"how many of the images have supervised labels\",\n",
        "    )\n",
        "    parser.add_argument(\n",
        "        \"-zd\",\n",
        "        \"--z-dim\",\n",
        "        default=50,\n",
        "        type=int,\n",
        "        help=\"size of the tensor representing the latent variable z \"\n",
        "        \"variable (handwriting style for our MNIST dataset)\",\n",
        "    )\n",
        "    parser.add_argument(\n",
        "        \"-hl\",\n",
        "        \"--hidden-layers\",\n",
        "        nargs=\"+\",\n",
        "        default=[500],\n",
        "        type=int,\n",
        "        help=\"a tuple (or list) of MLP layers to be used in the neural networks \"\n",
        "        \"representing the parameters of the distributions in our model\",\n",
        "    )\n",
        "    parser.add_argument(\n",
        "        \"-lr\",\n",
        "        \"--learning-rate\",\n",
        "        default=0.00042,\n",
        "        type=float,\n",
        "        help=\"learning rate for Adam optimizer\",\n",
        "    )\n",
        "    parser.add_argument(\n",
        "        \"-b1\",\n",
        "        \"--beta-1\",\n",
        "        default=0.9,\n",
        "        type=float,\n",
        "        help=\"beta-1 parameter for Adam optimizer\",\n",
        "    )\n",
        "    parser.add_argument(\n",
        "        \"-bs\",\n",
        "        \"--batch-size\",\n",
        "        default=200,\n",
        "        type=int,\n",
        "        help=\"number of images (and labels) to be considered in a batch\",\n",
        "    )\n",
        "    parser.add_argument(\n",
        "        \"-log\",\n",
        "        \"--logfile\",\n",
        "        default=\"./tmp.log\",\n",
        "        type=str,\n",
        "        help=\"filename for logging the outputs\",\n",
        "    )\n",
        "    parser.add_argument(\n",
        "        \"--seed\",\n",
        "        default=None,\n",
        "        type=int,\n",
        "        help=\"seed for controlling randomness in this example\",\n",
        "    )\n",
        "    parser.add_argument(\n",
        "        \"--visualize\",\n",
        "        action=\"store_true\",\n",
        "        help=\"use a visdom server to visualize the embeddings\",\n",
        "    )\n",
        "    args = parser.parse_args()\n",
        "\n",
        "    # some assertions to make sure that batching math assumptions are met\n",
        "    assert args.sup_num % args.batch_size == 0, \"assuming simplicity of batching math\"\n",
        "    assert (\n",
        "        MNISTCached.validation_size % args.batch_size == 0\n",
        "    ), \"batch size should divide the number of validation examples\"\n",
        "    assert (\n",
        "        MNISTCached.train_data_size % args.batch_size == 0\n",
        "    ), \"batch size doesn't divide total number of training data examples\"\n",
        "    assert (\n",
        "        MNISTCached.test_size % args.batch_size == 0\n",
        "    ), \"batch size should divide the number of test examples\"\n",
        "\n",
        "    main(args)"
      ],
      "metadata": {
        "id": "lGPZrW8PRsQs"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "sx9n1bPkM_H8"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "dsawtskTRghc"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}