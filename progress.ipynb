{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip3 install pyro_ppl"
      ],
      "metadata": {
        "id": "Ni0YB-vKYFSi",
        "outputId": "fdce879c-7443-4d4f-959b-fe02d4aec8f5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pyro_ppl\n",
            "  Downloading pyro_ppl-1.8.1-py3-none-any.whl (718 kB)\n",
            "\u001b[K     |████████████████████████████████| 718 kB 4.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from pyro_ppl) (3.3.0)\n",
            "Requirement already satisfied: tqdm>=4.36 in /usr/local/lib/python3.7/dist-packages (from pyro_ppl) (4.64.0)\n",
            "Requirement already satisfied: numpy>=1.7 in /usr/local/lib/python3.7/dist-packages (from pyro_ppl) (1.21.6)\n",
            "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from pyro_ppl) (1.11.0+cu113)\n",
            "Collecting pyro-api>=0.1.1\n",
            "  Downloading pyro_api-0.1.2-py3-none-any.whl (11 kB)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.11.0->pyro_ppl) (4.1.1)\n",
            "Installing collected packages: pyro-api, pyro-ppl\n",
            "Successfully installed pyro-api-0.1.2 pyro-ppl-1.8.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "id": "T0XMn_iAX_mW"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms\n",
        "import os\n",
        "from torchvision.transforms import ToTensor, Lambda\n",
        "\n",
        "from pyro.contrib.examples.util import MNIST\n",
        "import torch.nn as nn\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "import pyro\n",
        "import pyro.distributions as dist\n",
        "import pyro.contrib.examples.util  # patches torchvision\n",
        "from pyro.infer import SVI, Trace_ELBO\n",
        "from pyro.optim import Adam\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "MJ8Elu1ZX_ma"
      },
      "outputs": [],
      "source": [
        "assert pyro.__version__.startswith('1.8.1') # make sure we have Pyro 1.8.1\n",
        "pyro.distributions.enable_validation(False) \n",
        "pyro.set_rng_seed(0) # make results reproducible\n",
        "# Enable smoke test - run the notebook cells on CI.\n",
        "smoke_test = 'CI' in os.environ "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 195,
      "metadata": {
        "id": "nBELjXP0X_ma"
      },
      "outputs": [],
      "source": [
        "\n",
        "class TMNISTDataset(Dataset):\n",
        "    '''\n",
        "    Typeface MNIST Dataset\n",
        "\n",
        "    Input: 'path/to/csv/file' (Required)\n",
        "    Output: torch.utils.data.Dataset\n",
        "    \n",
        "    '''\n",
        "    def __init__(self, csv_file, root_dir='', transform=None, target_transform = Lambda(lambda y: torch.zeros(\n",
        "    10, dtype=torch.float).scatter_(dim=0, index=torch.tensor(y), value=1))):\n",
        "        '''\n",
        "        Args: csv_file (string): Path to the csv file with annotations.    \n",
        "        '''\n",
        "        self.tmnist_frame = pd.read_csv(csv_file)\n",
        "        self.transform = transform\n",
        "        self.root_dir = root_dir\n",
        "        self.target_transform = target_transform\n",
        "    def __len__(self):\n",
        "        return len(self.tmnist_frame)\n",
        "    \n",
        "    def __getitem__(self, idx):\n",
        "        if torch.is_tensor(idx):\n",
        "            idx = idx.tolist()\n",
        "        \n",
        "        digits = self.tmnist_frame.iloc[idx, 2:]\n",
        "        digits = np.array([digits])\n",
        "        digits = digits.reshape(28,28)\n",
        "        digits = digits.astype('float32')\n",
        "        label = self.tmnist_frame.iloc[idx, 1]\n",
        "        label = np.array([label])\n",
        "        label = label.astype('int64')\n",
        "\n",
        "        if self.transform:\n",
        "            digits = self.transform(digits)\n",
        "\n",
        "        return digits, label.squeeze()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 179,
      "metadata": {
        "id": "XnLahn1KX_mb"
      },
      "outputs": [],
      "source": [
        "# for loading and batching MNIST dataset\n",
        "def setup_data_loaders(batch_size=64, use_cuda=False): \n",
        "    root = './data'\n",
        "    download = True\n",
        "    # Define transforms\n",
        "    trans = transforms.ToTensor()\n",
        "    # train_set = MNIST(root=root, train=True, transform=trans, \n",
        "    #                   download=download)\n",
        "    # test_set = MNIST(root=root, train=False, transform=trans)\n",
        "    tmnist_dataset = tmnist_dataset = TMNISTDataset(\"https://raw.githubusercontent.com/prasadshreyas/CS7290-Causal-ML-PyTorch/main/data/TMNIST/TMNIST_Data.csv\", transform= transforms.ToTensor() )\n",
        "    n = len(tmnist_dataset)\n",
        "    train_length = int(n*0.7)\n",
        "    test_length = n - train_length\n",
        "    train_set,test_set = torch.utils.data.random_split( dataset = tmnist_dataset, lengths = [train_length,test_length], generator=torch.Generator().manual_seed(42))\n",
        "    \n",
        "    kwargs = {'num_workers': 1, 'pin_memory': use_cuda}\n",
        "    train_loader = torch.utils.data.DataLoader(dataset=train_set,\n",
        "        batch_size=batch_size, shuffle=True, **kwargs)\n",
        "    test_loader = torch.utils.data.DataLoader(dataset=test_set,\n",
        "        batch_size=batch_size, shuffle=False, **kwargs)\n",
        "    return train_loader, test_loader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 180,
      "metadata": {
        "id": "bvm31fF4X_mc"
      },
      "outputs": [],
      "source": [
        "class Encoder(nn.Module):\n",
        "    def __init__(self, z_dim, hidden_dim):\n",
        "        super().__init__()\n",
        "        # setup the three linear transformations used\n",
        "        self.fc1 = nn.Linear(784, hidden_dim) # 784 = 28 * 28 \n",
        "        self.fc21 = nn.Linear(hidden_dim, z_dim)\n",
        "        self.fc22 = nn.Linear(hidden_dim, z_dim)\n",
        "        # setup the non-linearities\n",
        "        self.softplus = nn.Softplus() # Softplus function is used to make sure the output is positive - RELU\n",
        "\n",
        "    def forward(self, x):\n",
        "        # define the forward computation on the image x\n",
        "        # first shape the mini-batch to have pixels in the rightmost dimension\n",
        "        x = x.reshape(-1, 784) \n",
        "        print(x)\n",
        "        # then compute the hidden units\n",
        "        hidden = self.softplus(self.fc1(x))\n",
        "        # then return a mean vector and a (positive) square root covariance\n",
        "        # each of size batch_size x z_dim\n",
        "        z_loc = self.fc21(hidden)\n",
        "        z_scale = torch.exp(self.fc22(hidden))\n",
        "        return z_loc, z_scale"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 181,
      "metadata": {
        "id": "yAYjLyS1X_md"
      },
      "outputs": [],
      "source": [
        "class Decoder(nn.Module):\n",
        "    def __init__(self, z_dim, hidden_dim):\n",
        "        super().__init__()\n",
        "        # setup the two linear transformations used\n",
        "        self.fc1 = nn.Linear(z_dim, hidden_dim)\n",
        "        self.fc21 = nn.Linear(hidden_dim, 784)\n",
        "        # setup the non-linearities\n",
        "        self.softplus = nn.Softplus()\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "    def forward(self, z):\n",
        "        # define the forward computation on the latent z\n",
        "        # first compute the hidden units\n",
        "        hidden = self.softplus(self.fc1(z))\n",
        "        # return the parameter for the output Bernoulli\n",
        "        # each is of size batch_size x 784\n",
        "        loc_img = self.sigmoid(self.fc21(hidden))\n",
        "        return loc_img"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 182,
      "metadata": {
        "id": "SlrZr826X_me"
      },
      "outputs": [],
      "source": [
        "# define the model p(x|z)p(z)\n",
        "def model(self, x):\n",
        "    # register PyTorch module `decoder` with Pyro\n",
        "    pyro.module(\"decoder\", self.decoder)\n",
        "    with pyro.plate(\"data\", x.shape[0]):\n",
        "        # setup hyperparameters for prior p(z)\n",
        "        z_loc = x.new_zeros(torch.Size((x.shape[0], self.z_dim)))\n",
        "        z_scale = x.new_ones(torch.Size((x.shape[0], self.z_dim)))\n",
        "        # sample from prior (value will be sampled by guide when computing the ELBO)\n",
        "        z = pyro.sample(\"latent\", dist.Normal(z_loc, z_scale).to_event(1))\n",
        "        # decode the latent code z\n",
        "        loc_img = self.decoder(z)\n",
        "        # score against actual images\n",
        "        pyro.sample(\"obs\", dist.Bernoulli(loc_img).to_event(1), obs=x.reshape(-1, 784))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 183,
      "metadata": {
        "id": "Dqb8OQbBX_mf"
      },
      "outputs": [],
      "source": [
        "# define the guide (i.e. variational distribution) q(z|x)\n",
        "def guide(self, x):\n",
        "    # register PyTorch module `encoder` with Pyro\n",
        "    pyro.module(\"encoder\", self.encoder)\n",
        "    with pyro.plate(\"data\", x.shape[0]):\n",
        "        # use the encoder to get the parameters used to define q(z|x)\n",
        "        z_loc, z_scale = self.encoder(x)\n",
        "        # sample the latent code z\n",
        "        pyro.sample(\"latent\", dist.Normal(z_loc, z_scale).to_event(1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 184,
      "metadata": {
        "id": "bsw4p_63X_mf"
      },
      "outputs": [],
      "source": [
        "class VAE(nn.Module):\n",
        "    # by default our latent space is 50-dimensional\n",
        "    # and we use 400 hidden units\n",
        "    def __init__(self, z_dim=50, hidden_dim=400, use_cuda=False):\n",
        "        super().__init__()\n",
        "        # create the encoder and decoder networks\n",
        "        self.encoder = Encoder(z_dim, hidden_dim)\n",
        "        self.decoder = Decoder(z_dim, hidden_dim)\n",
        "\n",
        "        if use_cuda:\n",
        "            # calling cuda() here will put all the parameters of\n",
        "            # the encoder and decoder networks into gpu memory\n",
        "            self.cuda()\n",
        "        self.use_cuda = use_cuda\n",
        "        self.z_dim = z_dim\n",
        "\n",
        "    # define the model p(x|z)p(z)\n",
        "    def model(self, x):\n",
        "        # register PyTorch module `decoder` with Pyro\n",
        "        pyro.module(\"decoder\", self.decoder)\n",
        "        with pyro.plate(\"data\", x.shape[0]):\n",
        "            # setup hyperparameters for prior p(z)\n",
        "            z_loc = x.new_zeros(torch.Size((x.shape[0], self.z_dim)))\n",
        "            z_scale = x.new_ones(torch.Size((x.shape[0], self.z_dim)))\n",
        "            # sample from prior (value will be sampled by guide when computing the ELBO)\n",
        "            z = pyro.sample(\"latent\", dist.Normal(z_loc, z_scale).to_event(1))\n",
        "            # decode the latent code z\n",
        "            loc_img = self.decoder(z)\n",
        "            # score against actual images\n",
        "            pyro.sample(\"obs\", dist.Bernoulli(loc_img).to_event(1), obs=x.reshape(-1, 784))\n",
        "\n",
        "    # define the guide (i.e. variational distribution) q(z|x)\n",
        "    def guide(self, x):\n",
        "        # register PyTorch module `encoder` with Pyro\n",
        "        pyro.module(\"encoder\", self.encoder)\n",
        "        with pyro.plate(\"data\", x.shape[0]):\n",
        "            # use the encoder to get the parameters used to define q(z|x)\n",
        "            z_loc, z_scale = self.encoder(x)\n",
        "            # sample the latent code z\n",
        "            pyro.sample(\"latent\", dist.Normal(z_loc, z_scale).to_event(1))\n",
        "\n",
        "    # define a helper function for reconstructing images\n",
        "    def reconstruct_img(self, x):\n",
        "        # encode image x\n",
        "        z_loc, z_scale = self.encoder(x)\n",
        "        # sample in latent space\n",
        "        z = dist.Normal(z_loc, z_scale).sample()\n",
        "        # decode the image (note we don't sample in image space)\n",
        "        loc_img = self.decoder(z)\n",
        "        return loc_img\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 185,
      "metadata": {
        "id": "U_SCP-f7X_mg"
      },
      "outputs": [],
      "source": [
        "vae = VAE()\n",
        "optimizer = Adam({\"lr\": 1.0e-3})\n",
        "svi = SVI(vae.model, vae.guide, optimizer, loss=Trace_ELBO())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 186,
      "metadata": {
        "id": "xPLCFdAMX_mh"
      },
      "outputs": [],
      "source": [
        "def train(svi, train_loader, use_cuda=False):\n",
        "    # initialize loss accumulator\n",
        "    epoch_loss = 0.\n",
        "    # do a training epoch over each mini-batch x returned\n",
        "    # by the data loader\n",
        "    for x, _ in train_loader:\n",
        "        # if on GPU put mini-batch into CUDA memory\n",
        "        if use_cuda:\n",
        "            x = x.cuda()\n",
        "        # do ELBO gradient and accumulate loss\n",
        "        epoch_loss += svi.step(x)\n",
        "\n",
        "    # return epoch loss\n",
        "    normalizer_train = len(train_loader.dataset)\n",
        "    total_epoch_loss_train = epoch_loss / normalizer_train\n",
        "    return total_epoch_loss_train\n",
        "\n",
        "def evaluate(svi, test_loader, use_cuda=False):\n",
        "    # initialize loss accumulator\n",
        "    test_loss = 0.\n",
        "    # compute the loss over the entire test set\n",
        "    for x, _ in test_loader:\n",
        "        # if on GPU put mini-batch into CUDA memory\n",
        "        if use_cuda:\n",
        "            x = x.cuda()\n",
        "        # compute ELBO estimate and accumulate loss\n",
        "        test_loss += svi.evaluate_loss(x)\n",
        "    normalizer_test = len(test_loader.dataset)\n",
        "    total_epoch_loss_test = test_loss / normalizer_test\n",
        "    return total_epoch_loss_test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 187,
      "metadata": {
        "id": "wowGvPW3X_mh"
      },
      "outputs": [],
      "source": [
        "# Run options\n",
        "LEARNING_RATE = 1.0e-3\n",
        "USE_CUDA = False\n",
        "\n",
        "# Run only for a single iteration for testing\n",
        "NUM_EPOCHS = 1 if smoke_test else 1\n",
        "TEST_FREQUENCY = 5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 188,
      "metadata": {
        "id": "hYWZJCldX_mh"
      },
      "outputs": [],
      "source": [
        "train_loader, test_loader = setup_data_loaders(batch_size=256, use_cuda=USE_CUDA)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 189,
      "metadata": {
        "id": "Rp7NwV-qX_mi"
      },
      "outputs": [],
      "source": [
        "\n",
        "# clear param store\n",
        "pyro.clear_param_store()\n",
        "\n",
        "# setup the VAE\n",
        "vae = VAE(use_cuda=USE_CUDA)\n",
        "\n",
        "# setup the optimizer\n",
        "adam_args = {\"lr\": LEARNING_RATE}\n",
        "optimizer = Adam(adam_args)\n",
        "\n",
        "# setup the inference algorithm\n",
        "svi = SVI(vae.model, vae.guide, optimizer, loss=Trace_ELBO())\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "train_elbo = []\n",
        "test_elbo = []\n",
        "# training loop\n",
        "for epoch in range(NUM_EPOCHS):\n",
        "    total_epoch_loss_train = train(svi, train_loader, use_cuda=USE_CUDA)\n",
        "    train_elbo.append(-total_epoch_loss_train)\n",
        "    print(\"[epoch %03d]  average training loss: %.4f\" % (epoch, total_epoch_loss_train))\n",
        "\n",
        "    if epoch % TEST_FREQUENCY == 0:\n",
        "        # report test diagnostics\n",
        "        total_epoch_loss_test = evaluate(svi, test_loader, use_cuda=USE_CUDA)\n",
        "        test_elbo.append(-total_epoch_loss_test)\n",
        "        print(\"[epoch %03d] average test loss: %.4f\" % (epoch, total_epoch_loss_test))"
      ],
      "metadata": {
        "id": "wL52lDpSFG3G",
        "outputId": "7e0c10ef-5c7c-41b5-bc80-02c6aa8c8041",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "execution_count": 194,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "        ...,\n",
            "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "        [0., 0., 0.,  ..., 0., 0., 0.]])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/pyro/poutine/trace_struct.py:286: UserWarning: Encountered NaN: log_prob_sum at site 'latent'\n",
            "  site[\"log_prob_sum\"], \"log_prob_sum at site '{}'\".format(name)\n",
            "/usr/local/lib/python3.7/dist-packages/pyro/infer/trace_elbo.py:158: UserWarning: Encountered NaN: loss\n",
            "  warn_if_nan(loss, \"loss\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "        ...,\n",
            "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "        [0., 0., 0.,  ..., 0., 0., 0.]])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/pyro/poutine/trace_struct.py:248: UserWarning: Encountered NaN: log_prob_sum at site 'latent'\n",
            "  \"log_prob_sum at site '{}'\".format(name),\n",
            "/usr/local/lib/python3.7/dist-packages/pyro/poutine/trace_struct.py:248: UserWarning: Encountered NaN: log_prob_sum at site 'obs'\n",
            "  \"log_prob_sum at site '{}'\".format(name),\n",
            "/usr/local/lib/python3.7/dist-packages/pyro/poutine/trace_struct.py:286: UserWarning: Encountered NaN: log_prob_sum at site 'latent'\n",
            "  site[\"log_prob_sum\"], \"log_prob_sum at site '{}'\".format(name)\n",
            "/usr/local/lib/python3.7/dist-packages/pyro/infer/trace_elbo.py:158: UserWarning: Encountered NaN: loss\n",
            "  warn_if_nan(loss, \"loss\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "        ...,\n",
            "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
            "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "        ...,\n",
            "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "        [0., 0., 0.,  ..., 0., 0., 0.]])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/pyro/poutine/trace_struct.py:248: UserWarning: Encountered NaN: log_prob_sum at site 'latent'\n",
            "  \"log_prob_sum at site '{}'\".format(name),\n",
            "/usr/local/lib/python3.7/dist-packages/pyro/poutine/trace_struct.py:248: UserWarning: Encountered NaN: log_prob_sum at site 'obs'\n",
            "  \"log_prob_sum at site '{}'\".format(name),\n",
            "/usr/local/lib/python3.7/dist-packages/pyro/poutine/trace_struct.py:286: UserWarning: Encountered NaN: log_prob_sum at site 'latent'\n",
            "  site[\"log_prob_sum\"], \"log_prob_sum at site '{}'\".format(name)\n",
            "/usr/local/lib/python3.7/dist-packages/pyro/infer/trace_elbo.py:158: UserWarning: Encountered NaN: loss\n",
            "  warn_if_nan(loss, \"loss\")\n",
            "/usr/local/lib/python3.7/dist-packages/pyro/poutine/trace_struct.py:248: UserWarning: Encountered NaN: log_prob_sum at site 'latent'\n",
            "  \"log_prob_sum at site '{}'\".format(name),\n",
            "/usr/local/lib/python3.7/dist-packages/pyro/poutine/trace_struct.py:248: UserWarning: Encountered NaN: log_prob_sum at site 'obs'\n",
            "  \"log_prob_sum at site '{}'\".format(name),\n",
            "/usr/local/lib/python3.7/dist-packages/pyro/poutine/trace_struct.py:286: UserWarning: Encountered NaN: log_prob_sum at site 'latent'\n",
            "  site[\"log_prob_sum\"], \"log_prob_sum at site '{}'\".format(name)\n",
            "/usr/local/lib/python3.7/dist-packages/pyro/infer/trace_elbo.py:158: UserWarning: Encountered NaN: loss\n",
            "  warn_if_nan(loss, \"loss\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "        ...,\n",
            "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "        [0., 0., 0.,  ..., 0., 0., 0.]])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/pyro/poutine/trace_struct.py:248: UserWarning: Encountered NaN: log_prob_sum at site 'latent'\n",
            "  \"log_prob_sum at site '{}'\".format(name),\n",
            "/usr/local/lib/python3.7/dist-packages/pyro/poutine/trace_struct.py:248: UserWarning: Encountered NaN: log_prob_sum at site 'obs'\n",
            "  \"log_prob_sum at site '{}'\".format(name),\n",
            "/usr/local/lib/python3.7/dist-packages/pyro/poutine/trace_struct.py:286: UserWarning: Encountered NaN: log_prob_sum at site 'latent'\n",
            "  site[\"log_prob_sum\"], \"log_prob_sum at site '{}'\".format(name)\n",
            "/usr/local/lib/python3.7/dist-packages/pyro/infer/trace_elbo.py:158: UserWarning: Encountered NaN: loss\n",
            "  warn_if_nan(loss, \"loss\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "        ...,\n",
            "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "        [0., 0., 0.,  ..., 0., 0., 0.]])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/pyro/poutine/trace_struct.py:248: UserWarning: Encountered NaN: log_prob_sum at site 'latent'\n",
            "  \"log_prob_sum at site '{}'\".format(name),\n",
            "/usr/local/lib/python3.7/dist-packages/pyro/poutine/trace_struct.py:248: UserWarning: Encountered NaN: log_prob_sum at site 'obs'\n",
            "  \"log_prob_sum at site '{}'\".format(name),\n",
            "/usr/local/lib/python3.7/dist-packages/pyro/poutine/trace_struct.py:286: UserWarning: Encountered NaN: log_prob_sum at site 'latent'\n",
            "  site[\"log_prob_sum\"], \"log_prob_sum at site '{}'\".format(name)\n",
            "/usr/local/lib/python3.7/dist-packages/pyro/infer/trace_elbo.py:158: UserWarning: Encountered NaN: loss\n",
            "  warn_if_nan(loss, \"loss\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "        ...,\n",
            "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "        [0., 0., 0.,  ..., 0., 0., 0.]])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/pyro/poutine/trace_struct.py:248: UserWarning: Encountered NaN: log_prob_sum at site 'latent'\n",
            "  \"log_prob_sum at site '{}'\".format(name),\n",
            "/usr/local/lib/python3.7/dist-packages/pyro/poutine/trace_struct.py:248: UserWarning: Encountered NaN: log_prob_sum at site 'obs'\n",
            "  \"log_prob_sum at site '{}'\".format(name),\n",
            "/usr/local/lib/python3.7/dist-packages/pyro/poutine/trace_struct.py:286: UserWarning: Encountered NaN: log_prob_sum at site 'latent'\n",
            "  site[\"log_prob_sum\"], \"log_prob_sum at site '{}'\".format(name)\n",
            "/usr/local/lib/python3.7/dist-packages/pyro/infer/trace_elbo.py:158: UserWarning: Encountered NaN: loss\n",
            "  warn_if_nan(loss, \"loss\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "        ...,\n",
            "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "        [0., 0., 0.,  ..., 0., 0., 0.]])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/pyro/poutine/trace_struct.py:248: UserWarning: Encountered NaN: log_prob_sum at site 'latent'\n",
            "  \"log_prob_sum at site '{}'\".format(name),\n",
            "/usr/local/lib/python3.7/dist-packages/pyro/poutine/trace_struct.py:248: UserWarning: Encountered NaN: log_prob_sum at site 'obs'\n",
            "  \"log_prob_sum at site '{}'\".format(name),\n",
            "/usr/local/lib/python3.7/dist-packages/pyro/poutine/trace_struct.py:286: UserWarning: Encountered NaN: log_prob_sum at site 'latent'\n",
            "  site[\"log_prob_sum\"], \"log_prob_sum at site '{}'\".format(name)\n",
            "/usr/local/lib/python3.7/dist-packages/pyro/infer/trace_elbo.py:158: UserWarning: Encountered NaN: loss\n",
            "  warn_if_nan(loss, \"loss\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "        ...,\n",
            "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "        [0., 0., 0.,  ..., 0., 0., 0.]])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/pyro/poutine/trace_struct.py:248: UserWarning: Encountered NaN: log_prob_sum at site 'latent'\n",
            "  \"log_prob_sum at site '{}'\".format(name),\n",
            "/usr/local/lib/python3.7/dist-packages/pyro/poutine/trace_struct.py:248: UserWarning: Encountered NaN: log_prob_sum at site 'obs'\n",
            "  \"log_prob_sum at site '{}'\".format(name),\n",
            "/usr/local/lib/python3.7/dist-packages/pyro/poutine/trace_struct.py:286: UserWarning: Encountered NaN: log_prob_sum at site 'latent'\n",
            "  site[\"log_prob_sum\"], \"log_prob_sum at site '{}'\".format(name)\n",
            "/usr/local/lib/python3.7/dist-packages/pyro/infer/trace_elbo.py:158: UserWarning: Encountered NaN: loss\n",
            "  warn_if_nan(loss, \"loss\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "        ...,\n",
            "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "        [0., 0., 0.,  ..., 0., 0., 0.]])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/pyro/poutine/trace_struct.py:248: UserWarning: Encountered NaN: log_prob_sum at site 'latent'\n",
            "  \"log_prob_sum at site '{}'\".format(name),\n",
            "/usr/local/lib/python3.7/dist-packages/pyro/poutine/trace_struct.py:248: UserWarning: Encountered NaN: log_prob_sum at site 'obs'\n",
            "  \"log_prob_sum at site '{}'\".format(name),\n",
            "/usr/local/lib/python3.7/dist-packages/pyro/poutine/trace_struct.py:286: UserWarning: Encountered NaN: log_prob_sum at site 'latent'\n",
            "  site[\"log_prob_sum\"], \"log_prob_sum at site '{}'\".format(name)\n",
            "/usr/local/lib/python3.7/dist-packages/pyro/infer/trace_elbo.py:158: UserWarning: Encountered NaN: loss\n",
            "  warn_if_nan(loss, \"loss\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "        ...,\n",
            "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "        [0., 0., 0.,  ..., 0., 0., 0.]])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/pyro/poutine/trace_struct.py:248: UserWarning: Encountered NaN: log_prob_sum at site 'latent'\n",
            "  \"log_prob_sum at site '{}'\".format(name),\n",
            "/usr/local/lib/python3.7/dist-packages/pyro/poutine/trace_struct.py:248: UserWarning: Encountered NaN: log_prob_sum at site 'obs'\n",
            "  \"log_prob_sum at site '{}'\".format(name),\n",
            "/usr/local/lib/python3.7/dist-packages/pyro/poutine/trace_struct.py:286: UserWarning: Encountered NaN: log_prob_sum at site 'latent'\n",
            "  site[\"log_prob_sum\"], \"log_prob_sum at site '{}'\".format(name)\n",
            "/usr/local/lib/python3.7/dist-packages/pyro/infer/trace_elbo.py:158: UserWarning: Encountered NaN: loss\n",
            "  warn_if_nan(loss, \"loss\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "        ...,\n",
            "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "        [0., 0., 0.,  ..., 0., 0., 0.]])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/pyro/poutine/trace_struct.py:248: UserWarning: Encountered NaN: log_prob_sum at site 'latent'\n",
            "  \"log_prob_sum at site '{}'\".format(name),\n",
            "/usr/local/lib/python3.7/dist-packages/pyro/poutine/trace_struct.py:248: UserWarning: Encountered NaN: log_prob_sum at site 'obs'\n",
            "  \"log_prob_sum at site '{}'\".format(name),\n",
            "/usr/local/lib/python3.7/dist-packages/pyro/poutine/trace_struct.py:286: UserWarning: Encountered NaN: log_prob_sum at site 'latent'\n",
            "  site[\"log_prob_sum\"], \"log_prob_sum at site '{}'\".format(name)\n",
            "/usr/local/lib/python3.7/dist-packages/pyro/infer/trace_elbo.py:158: UserWarning: Encountered NaN: loss\n",
            "  warn_if_nan(loss, \"loss\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "        ...,\n",
            "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "        [0., 0., 0.,  ..., 0., 0., 0.]])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/pyro/poutine/trace_struct.py:248: UserWarning: Encountered NaN: log_prob_sum at site 'latent'\n",
            "  \"log_prob_sum at site '{}'\".format(name),\n",
            "/usr/local/lib/python3.7/dist-packages/pyro/poutine/trace_struct.py:248: UserWarning: Encountered NaN: log_prob_sum at site 'obs'\n",
            "  \"log_prob_sum at site '{}'\".format(name),\n",
            "/usr/local/lib/python3.7/dist-packages/pyro/poutine/trace_struct.py:286: UserWarning: Encountered NaN: log_prob_sum at site 'latent'\n",
            "  site[\"log_prob_sum\"], \"log_prob_sum at site '{}'\".format(name)\n",
            "/usr/local/lib/python3.7/dist-packages/pyro/infer/trace_elbo.py:158: UserWarning: Encountered NaN: loss\n",
            "  warn_if_nan(loss, \"loss\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "        ...,\n",
            "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "        [0., 0., 0.,  ..., 0., 0., 0.]])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/pyro/poutine/trace_struct.py:248: UserWarning: Encountered NaN: log_prob_sum at site 'latent'\n",
            "  \"log_prob_sum at site '{}'\".format(name),\n",
            "/usr/local/lib/python3.7/dist-packages/pyro/poutine/trace_struct.py:248: UserWarning: Encountered NaN: log_prob_sum at site 'obs'\n",
            "  \"log_prob_sum at site '{}'\".format(name),\n",
            "/usr/local/lib/python3.7/dist-packages/pyro/poutine/trace_struct.py:286: UserWarning: Encountered NaN: log_prob_sum at site 'latent'\n",
            "  site[\"log_prob_sum\"], \"log_prob_sum at site '{}'\".format(name)\n",
            "/usr/local/lib/python3.7/dist-packages/pyro/infer/trace_elbo.py:158: UserWarning: Encountered NaN: loss\n",
            "  warn_if_nan(loss, \"loss\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "        ...,\n",
            "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "        [0., 0., 0.,  ..., 0., 0., 0.]])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/pyro/poutine/trace_struct.py:248: UserWarning: Encountered NaN: log_prob_sum at site 'latent'\n",
            "  \"log_prob_sum at site '{}'\".format(name),\n",
            "/usr/local/lib/python3.7/dist-packages/pyro/poutine/trace_struct.py:248: UserWarning: Encountered NaN: log_prob_sum at site 'obs'\n",
            "  \"log_prob_sum at site '{}'\".format(name),\n",
            "/usr/local/lib/python3.7/dist-packages/pyro/poutine/trace_struct.py:286: UserWarning: Encountered NaN: log_prob_sum at site 'latent'\n",
            "  site[\"log_prob_sum\"], \"log_prob_sum at site '{}'\".format(name)\n",
            "/usr/local/lib/python3.7/dist-packages/pyro/infer/trace_elbo.py:158: UserWarning: Encountered NaN: loss\n",
            "  warn_if_nan(loss, \"loss\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "        ...,\n",
            "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "        [0., 0., 0.,  ..., 0., 0., 0.]])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/pyro/poutine/trace_struct.py:248: UserWarning: Encountered NaN: log_prob_sum at site 'latent'\n",
            "  \"log_prob_sum at site '{}'\".format(name),\n",
            "/usr/local/lib/python3.7/dist-packages/pyro/poutine/trace_struct.py:248: UserWarning: Encountered NaN: log_prob_sum at site 'obs'\n",
            "  \"log_prob_sum at site '{}'\".format(name),\n",
            "/usr/local/lib/python3.7/dist-packages/pyro/poutine/trace_struct.py:286: UserWarning: Encountered NaN: log_prob_sum at site 'latent'\n",
            "  site[\"log_prob_sum\"], \"log_prob_sum at site '{}'\".format(name)\n",
            "/usr/local/lib/python3.7/dist-packages/pyro/infer/trace_elbo.py:158: UserWarning: Encountered NaN: loss\n",
            "  warn_if_nan(loss, \"loss\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "        ...,\n",
            "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "        [0., 0., 0.,  ..., 0., 0., 0.]])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/pyro/poutine/trace_struct.py:248: UserWarning: Encountered NaN: log_prob_sum at site 'latent'\n",
            "  \"log_prob_sum at site '{}'\".format(name),\n",
            "/usr/local/lib/python3.7/dist-packages/pyro/poutine/trace_struct.py:248: UserWarning: Encountered NaN: log_prob_sum at site 'obs'\n",
            "  \"log_prob_sum at site '{}'\".format(name),\n",
            "/usr/local/lib/python3.7/dist-packages/pyro/poutine/trace_struct.py:286: UserWarning: Encountered NaN: log_prob_sum at site 'latent'\n",
            "  site[\"log_prob_sum\"], \"log_prob_sum at site '{}'\".format(name)\n",
            "/usr/local/lib/python3.7/dist-packages/pyro/infer/trace_elbo.py:158: UserWarning: Encountered NaN: loss\n",
            "  warn_if_nan(loss, \"loss\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "        ...,\n",
            "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "        [0., 0., 0.,  ..., 0., 0., 0.]])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/pyro/poutine/trace_struct.py:248: UserWarning: Encountered NaN: log_prob_sum at site 'latent'\n",
            "  \"log_prob_sum at site '{}'\".format(name),\n",
            "/usr/local/lib/python3.7/dist-packages/pyro/poutine/trace_struct.py:248: UserWarning: Encountered NaN: log_prob_sum at site 'obs'\n",
            "  \"log_prob_sum at site '{}'\".format(name),\n",
            "/usr/local/lib/python3.7/dist-packages/pyro/poutine/trace_struct.py:286: UserWarning: Encountered NaN: log_prob_sum at site 'latent'\n",
            "  site[\"log_prob_sum\"], \"log_prob_sum at site '{}'\".format(name)\n",
            "/usr/local/lib/python3.7/dist-packages/pyro/infer/trace_elbo.py:158: UserWarning: Encountered NaN: loss\n",
            "  warn_if_nan(loss, \"loss\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "        ...,\n",
            "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "        [0., 0., 0.,  ..., 0., 0., 0.]])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/pyro/poutine/trace_struct.py:248: UserWarning: Encountered NaN: log_prob_sum at site 'latent'\n",
            "  \"log_prob_sum at site '{}'\".format(name),\n",
            "/usr/local/lib/python3.7/dist-packages/pyro/poutine/trace_struct.py:248: UserWarning: Encountered NaN: log_prob_sum at site 'obs'\n",
            "  \"log_prob_sum at site '{}'\".format(name),\n",
            "/usr/local/lib/python3.7/dist-packages/pyro/poutine/trace_struct.py:286: UserWarning: Encountered NaN: log_prob_sum at site 'latent'\n",
            "  site[\"log_prob_sum\"], \"log_prob_sum at site '{}'\".format(name)\n",
            "/usr/local/lib/python3.7/dist-packages/pyro/infer/trace_elbo.py:158: UserWarning: Encountered NaN: loss\n",
            "  warn_if_nan(loss, \"loss\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "        ...,\n",
            "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "        [0., 0., 0.,  ..., 0., 0., 0.]])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/pyro/poutine/trace_struct.py:248: UserWarning: Encountered NaN: log_prob_sum at site 'latent'\n",
            "  \"log_prob_sum at site '{}'\".format(name),\n",
            "/usr/local/lib/python3.7/dist-packages/pyro/poutine/trace_struct.py:248: UserWarning: Encountered NaN: log_prob_sum at site 'obs'\n",
            "  \"log_prob_sum at site '{}'\".format(name),\n",
            "/usr/local/lib/python3.7/dist-packages/pyro/poutine/trace_struct.py:286: UserWarning: Encountered NaN: log_prob_sum at site 'latent'\n",
            "  site[\"log_prob_sum\"], \"log_prob_sum at site '{}'\".format(name)\n",
            "/usr/local/lib/python3.7/dist-packages/pyro/infer/trace_elbo.py:158: UserWarning: Encountered NaN: loss\n",
            "  warn_if_nan(loss, \"loss\")\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-194-86b8958d5041>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# training loop\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mNUM_EPOCHS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mtotal_epoch_loss_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msvi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_cuda\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mUSE_CUDA\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0mtrain_elbo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mtotal_epoch_loss_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"[epoch %03d]  average training loss: %.4f\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal_epoch_loss_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-186-66003a42bd66>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(svi, train_loader, use_cuda)\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;31m# do a training epoch over each mini-batch x returned\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;31m# by the data loader\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m         \u001b[0;31m# if on GPU put mini-batch into CUDA memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0muse_cuda\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    528\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    529\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 530\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    531\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    532\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1205\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1206\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_shutdown\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1207\u001b[0;31m             \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1208\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1209\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_get_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1171\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1172\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1173\u001b[0;31m                 \u001b[0msuccess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1174\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0msuccess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1175\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1009\u001b[0m         \u001b[0;31m#   (bool: whether successfully get data, any: data if successful else None)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1010\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1011\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data_queue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1012\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1013\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/multiprocessing/queues.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    111\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_rlock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelease\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m         \u001b[0;31m# unserialize the data after having released the lock\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_ForkingPickler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    114\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mqsize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/multiprocessing/reductions.py\u001b[0m in \u001b[0;36mrebuild_storage_fd\u001b[0;34m(cls, df, size)\u001b[0m\n\u001b[1;32m    293\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mrebuild_storage_fd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 295\u001b[0;31m     \u001b[0mfd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    296\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    297\u001b[0m         \u001b[0mstorage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstorage_from_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfd_id\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/multiprocessing/resource_sharer.py\u001b[0m in \u001b[0;36mdetach\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     55\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m             \u001b[0;34m'''Get the fd.  This should only be called once.'''\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m             \u001b[0;32mwith\u001b[0m \u001b[0m_resource_sharer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_connection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_id\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mconn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_handle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/multiprocessing/resource_sharer.py\u001b[0m in \u001b[0;36mget_connection\u001b[0;34m(ident)\u001b[0m\n\u001b[1;32m     85\u001b[0m         \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mconnection\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mClient\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m         \u001b[0maddress\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mident\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 87\u001b[0;31m         \u001b[0mc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mClient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maddress\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mauthkey\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprocess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcurrent_process\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauthkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m         \u001b[0mc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetpid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/multiprocessing/connection.py\u001b[0m in \u001b[0;36mClient\u001b[0;34m(address, family, authkey)\u001b[0m\n\u001b[1;32m    496\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    497\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mauthkey\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 498\u001b[0;31m         \u001b[0manswer_challenge\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mauthkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    499\u001b[0m         \u001b[0mdeliver_challenge\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mauthkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    500\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/multiprocessing/connection.py\u001b[0m in \u001b[0;36manswer_challenge\u001b[0;34m(connection, authkey)\u001b[0m\n\u001b[1;32m    740\u001b[0m         raise ValueError(\n\u001b[1;32m    741\u001b[0m             \"Authkey must be bytes, not {0!s}\".format(type(authkey)))\n\u001b[0;32m--> 742\u001b[0;31m     \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconnection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_bytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m256\u001b[0m\u001b[0;34m)\u001b[0m         \u001b[0;31m# reject large message\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    743\u001b[0m     \u001b[0;32massert\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mCHALLENGE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mCHALLENGE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'message = %r'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    744\u001b[0m     \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mCHALLENGE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/multiprocessing/connection.py\u001b[0m in \u001b[0;36mrecv_bytes\u001b[0;34m(self, maxlength)\u001b[0m\n\u001b[1;32m    214\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmaxlength\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mmaxlength\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"negative maxlength\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m         \u001b[0mbuf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_recv_bytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaxlength\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbuf\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_bad_message_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/multiprocessing/connection.py\u001b[0m in \u001b[0;36m_recv_bytes\u001b[0;34m(self, maxsize)\u001b[0m\n\u001b[1;32m    405\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    406\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_recv_bytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaxsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 407\u001b[0;31m         \u001b[0mbuf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_recv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    408\u001b[0m         \u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstruct\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munpack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"!i\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetvalue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    409\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmaxsize\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0msize\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mmaxsize\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/multiprocessing/connection.py\u001b[0m in \u001b[0;36m_recv\u001b[0;34m(self, size, read)\u001b[0m\n\u001b[1;32m    377\u001b[0m         \u001b[0mremaining\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    378\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0mremaining\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 379\u001b[0;31m             \u001b[0mchunk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mremaining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    380\u001b[0m             \u001b[0mn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    381\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mn\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Loading the dataset\n",
        "tmnist_dataset = TMNISTDataset(\"https://raw.githubusercontent.com/prasadshreyas/CS7290-Causal-ML-PyTorch/main/data/TMNIST/TMNIST_Data.csv\", transform= transforms.ToTensor())\n",
        "\n",
        "# Example of a sample\n",
        "# for i in range(len(tmnist_dataset)):\n",
        "#     sample = tmnist_dataset[i]\n",
        "#     print(i, sample[0].shape, sample[1].shape)\n",
        "#     if i == 1:\n",
        "#         break\n",
        "\n",
        "# Creating data loader\n",
        "dataloader = DataLoader(tmnist_dataset, batch_size=256,\n",
        "                        shuffle=True)     \n",
        "\n",
        "# # Quick glance at the batch\n",
        "# for x, y in dataloader:\n",
        "#     print(f\"Feature batch shape: {x.size()}\")\n",
        "#     print(f\"Labels batch shape: {y.size()}\")\n",
        "#     break\n",
        "\n",
        "\n",
        "# train_features, train_labels = next(iter(\n",
        "\n",
        "# Building the image grid\n",
        "train_features, train_labels = next(iter(dataloader))\n",
        "\n",
        "print(f\"Feature batch shape: {train_features.size()}\") \n",
        "print(f\"Labels batch shape: {train_labels.size()}\")\n",
        "img = train_features[0].squeeze()\n",
        "label = train_labels[0]\n",
        "import matplotlib.pyplot as plt \n",
        "plt.imshow(img, cmap=\"gray\")\n",
        "plt.show()\n",
        "print(f\"Label: {label}\")"
      ],
      "metadata": {
        "id": "BH8agY7Tc-67",
        "outputId": "93526503-c1f9-4d96-a9e1-3c085da6d870",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 317
        }
      },
      "execution_count": 193,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Feature batch shape: torch.Size([256, 1, 28, 28])\n",
            "Labels batch shape: torch.Size([256])\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Label: 2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_features[0].type()"
      ],
      "metadata": {
        "id": "86dsFCVmzPaj",
        "outputId": "9043e83a-7060-464a-b383-759f5e51d8a8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "execution_count": 191,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'torch.FloatTensor'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 191
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_labels"
      ],
      "metadata": {
        "id": "eKN2zvxoDyQV",
        "outputId": "192850aa-b26e-4746-8209-2129cbae40fd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 192,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([5, 6, 5, 5, 9, 6, 3, 4, 9, 6, 1, 7, 8, 7, 9, 5, 6, 0, 3, 3, 0, 9, 7, 7,\n",
              "        3, 8, 2, 7, 0, 2, 7, 4, 6, 2, 1, 9, 0, 9, 4, 0, 0, 5, 3, 2, 6, 1, 9, 8,\n",
              "        0, 1, 0, 5, 2, 2, 1, 7, 6, 3, 7, 6, 3, 4, 9, 0, 8, 8, 1, 3, 7, 6, 7, 6,\n",
              "        8, 9, 3, 7, 2, 6, 2, 2, 7, 8, 9, 2, 1, 9, 5, 4, 7, 1, 8, 7, 6, 0, 3, 4,\n",
              "        3, 7, 5, 8, 8, 6, 7, 4, 5, 6, 4, 5, 3, 0, 0, 5, 9, 2, 4, 6, 8, 7, 9, 7,\n",
              "        0, 0, 3, 7, 4, 8, 8, 7, 8, 8, 8, 4, 8, 3, 0, 8, 7, 6, 5, 7, 2, 9, 9, 7,\n",
              "        7, 7, 0, 6, 8, 6, 1, 6, 4, 5, 5, 7, 8, 9, 1, 2, 0, 3, 1, 6, 5, 5, 7, 4,\n",
              "        0, 8, 8, 3, 7, 6, 3, 9, 0, 6, 5, 8, 4, 1, 9, 9, 9, 4, 9, 0, 9, 4, 6, 2,\n",
              "        0, 1, 4, 3, 4, 9, 4, 8, 7, 9, 1, 5, 7, 1, 5, 5, 6, 8, 6, 8, 1, 4, 0, 3,\n",
              "        7, 9, 9, 1, 5, 7, 0, 7, 3, 2, 7, 1, 4, 0, 9, 4, 9, 1, 7, 7, 2, 2, 6, 6,\n",
              "        8, 9, 4, 0, 1, 6, 5, 6, 4, 9, 5, 0, 4, 7, 7, 5])"
            ]
          },
          "metadata": {},
          "execution_count": 192
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "ZufFJIsYMLyM"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "interpreter": {
      "hash": "44aac8fa55270aab16cf28b0bf1e5c8bf3de462e9a8a50d0b321a892ef2c99fa"
    },
    "kernelspec": {
      "display_name": "Python 3.9.7",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    },
    "orig_nbformat": 4,
    "colab": {
      "name": "progress.ipynb",
      "provenance": []
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}